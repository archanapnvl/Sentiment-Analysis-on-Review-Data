---
title: Assignment 4 - Text Mining
author: "Ritu, Nikita and Archana"
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#loading Packages
```{r}
library('tidyverse')
library(tidytext)
library(SnowballC)
library(textstem)
library(textdata)
library(ranger)
library(rsample)
library(pROC)
```

```{r}
#read excel
resReviewsData <- read_csv2("C:/Users/nikit/Desktop/IDS_572/Assignment4/yelpResReviewSample.csv")

#converting text to character
resReviewsData$text <- as.character(resReviewsData$text)
```

#Q1
# ##########################
#Part (a) - Data Exploration
# ##########################
```{r}
#Star Ratings vs No. of reviews
Table <- resReviewsData %>% group_by(stars) %>% count()
Table
write.csv(Table, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/Table.csv")
ggplot(resReviewsData, aes(x=stars)) + geom_bar(width = 0.5, fill = "#FF6666") + xlab("Stars") + ylab("No. of Reviews")

#State vs No. of reviews
Table <- resReviewsData %>% group_by(state) %>% count()
Table
write.csv(Table, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/Table.csv")
ggplot(resReviewsData, aes(x=state)) + geom_bar(width = 0.5, fill = "#FF6666") + xlab("State") + ylab("No. of Reviews")

#No of reviews for different Postal Length
table <- resReviewsData %>% group_by(postal_code) %>% count() %>% arrange(desc(n))
table <- ungroup(table)
top_postal_code <- table %>% top_n(20)
write.csv(top_postal_code, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/top_postal_code.csv")
ggplot(top_postal_code, aes(x=postal_code, y=n)) + geom_bar(stat="identity",  width = 0.5, fill = "#FF6666") + xlab("Postal Code") + ylab("No. of Reviews")

#Review length for different star ratings
#ggplot(resReviewsData, aes(x=nchar(text), fill=nchar(text))) + geom_bar(width = 0.5, fill = "#FF6666") + facet_wrap(~stars) + xlab("Review Text Length")

#Star ratings vs review length
#resReviewsData$stars <- as.factor(resReviewsData$stars)
#ggplot(resReviewsData, aes(x=stars, y=nchar(text), fill=stars)) + geom_boxplot(width = 0.5) + xlab("Stars") + ylab("Review Text Length")
#resReviewsData$stars <- as.integer(resReviewsData$stars)

#Star Ratings vs Cool reaction
ggplot(resReviewsData, aes(x=stars, y=cool, fill=stars)) + geom_bar(stat= "identity") + xlab("Stars") + ylab("Cool")
graph1 <- resReviewsData %>% group_by(stars) %>% summarize(mean(cool))
ggplot(graph1) + aes(x=graph1$stars, y=graph1$`mean(cool)`, fill=graph1$stars) + geom_line() + xlab("Stars") + ylab("Average of Cool Reaction")

#Star Ratings vs Funny reaction
ggplot(resReviewsData, aes(x=stars, y=funny, fill=stars)) + geom_bar(stat= "identity") + xlab("Stars") + ylab("Funny")
graph1 <- resReviewsData %>% group_by(stars) %>% summarize(mean(funny))
ggplot(graph1) + aes(x=graph1$stars, y=graph1$`mean(funny)`, fill=graph1$stars) + geom_line() + xlab("Stars") + ylab("Average of Funny Reaction")

#Star Ratings vs Useful reaction
ggplot(resReviewsData, aes(x=stars, y=useful, fill=stars)) + geom_bar(stat= "identity") + xlab("Stars") + ylab("Useful")
graph1 <- resReviewsData %>% group_by(stars) %>% summarize(mean(useful))
ggplot(graph1) + aes(x=graph1$stars, y=graph1$`mean(useful)`, fill=graph1$stars) + geom_line() + xlab("Stars") + ylab("Average of Useful Reaction")

#Dimensions for resReviewsData 
resReviewsData %>% dim()
#Reviews only from 5 digit postal codes
rrData <- resReviewsData %>% filter(str_detect(postal_code, "^[0-9]{1,5}"))
#Dimensions for rrData
rrData %>% dim()
```

#Q2
# #######################
#Part (b) - Data Cleaning
# #######################

# ################### General Cleaning Steps ##########################
```{r}
#tokenize the text of the reviews in the column named 'text'
rrTokens <- rrData %>% unnest_tokens(word, text)
#Dimensions for rrTokens
rrTokens %>% dim()
#Dimensions for the distinct word tokens
rrTokens %>% distinct(word) %>% dim()

#Remove non alphabetic characters
rrTokens<-rrTokens %>%  filter(!str_detect(word, "[^[:alpha:]]"))
#Dimensions for rrTokens
rrTokens %>% dim()
#Dimensions for the distinct word tokens
rrTokens %>% distinct(word) %>% dim()

#Remove stopwords
rrTokens<-rrTokens %>%  anti_join(stop_words, by = "word")
#Dimensions for rrTokens
rrTokens %>% dim()
#Dimensions for the distinct word tokens
rrTokens %>% distinct(word) %>% dim()

#Stemming
rrTokens<-rrTokens %>%  mutate(word_stem = SnowballC::wordStem(word))
#Dimensions for rrTokens
rrTokens %>% dim()
#Dimensions for the distinct word_stem tokens
rrTokens %>% distinct(word_stem) %>% dim()

#Lemmatization
rrTokens<-rrTokens %>%  mutate(word_lemma = textstem::lemmatize_words(word))
#Dimensions for rrTokens
rrTokens %>% dim()
#Dimensions for the distinct word_lemma tokens
rrTokens %>% distinct(word_lemma) %>% dim()

#We move ahead with Lemmatization
rrTokens<-rrTokens %>%  mutate(word = textstem::lemmatize_words(word)) %>% select(-word_stem, -word_lemma)
#Dimensions for rrTokens
rrTokens %>% dim()
#Dimensions for the distinct word_stem tokens
rrTokens %>% distinct(word) %>% dim()

#Filter out words with less than 3 characters and those with more than 15 characters
set_1<-rrTokens %>% filter(str_length(word)<=2)
set_2<-rrTokens %>% filter(str_length(word)>=16)
#Remove such words
rrTokens<-anti_join(rrTokens, set_1)
rrTokens<-anti_join(rrTokens, set_2)
#Dimensions for rrTokens
rrTokens %>% dim()
#Dimensions for the distinct word tokens
rrTokens %>% distinct(word) %>% dim()

# ################### Data Specific Cleaning Steps ####################

#count the total occurrences for different words and sort in desc order
table1 <- rrTokens %>% count(word, sort=TRUE) %>% top_n(20)
write.csv(table1, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/Table1.csv")
ggplot(table1, aes(x=table1$word, y=table1$n)) + geom_bar(stat="identity", fill="#CC0000", color="#FFFFFF") + coord_flip() + scale_y_continuous(name="Occurence") + scale_x_discrete(name="Top 20 most frequent words") + theme(axis.text.y = element_text(face = "bold", size = 10))

#rare words (occurence less than 10)
rareWords <-rrTokens %>% count(word, sort=TRUE) %>% filter(n<10)
#dimension for distinct rare words
rareWords %>% distinct(word) %>% dim()
#remove rare words
rrTokens<-anti_join(rrTokens, rareWords)
#Dimensions for rrTokens
rrTokens %>% dim()
#dimension for distinct words after removing rare words
rrTokens %>% distinct(word) %>% dim()

#proportion of word occurrence wrt different star ratings
ws<-rrTokens %>% group_by(stars) %>% count(word, sort=TRUE)
ws<-ws %>% group_by(stars) %>% mutate(prop=n/sum(n)) %>% arrange(desc(stars, prop))

#proportion of word occurrence wrt different star ratings (top 20 for each)
table2 <- ws %>% group_by(stars) %>% arrange(stars, desc(prop)) %>% top_n(20)
write.csv(table2, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/Table2.csv")
#1 star rating
star1 <- table2 %>% filter(stars=='1') %>% arrange(desc(prop))
ggplot(star1, aes(x=star1$word, y=star1$prop, fill=star1$word)) + geom_bar(stat="identity") + coord_flip() + scale_y_continuous(name="Proportion of word") + scale_x_discrete(name="Top 20 most frequent words of Star 1") + theme(axis.text.y = element_text(hjust = 1, size = 8, face = "bold"))
#2 star rating
star2 <- table2 %>% filter(stars=='2') %>% arrange(desc(prop))
ggplot(star2, aes(x=star2$word, y=star2$prop, fill=star2$word)) + geom_bar(stat="identity") + coord_flip() + scale_y_continuous(name="Proportion of word") + scale_x_discrete(name="Top 20 most frequent words of Star 2") + theme(axis.text.y = element_text(hjust = 1, size = 8, face = "bold"))
#3 star rating
star3 <- table2 %>% filter(stars=='3') %>% arrange(desc(prop))
ggplot(star3, aes(x=star3$word, y=star3$prop, fill=star3$word)) + geom_bar(stat="identity") + coord_flip() + scale_y_continuous(name="Proportion of word") + scale_x_discrete(name="Top 20 most frequent words of Star 3") + theme(axis.text.y = element_text(hjust = 1, size = 8, face = "bold"))
#4 star rating
star4 <- table2 %>% filter(stars=='4') %>% arrange(desc(prop))
ggplot(star4, aes(x=star4$word, y=star4$prop, fill=star4$word)) + geom_bar(stat="identity") + coord_flip() + scale_y_continuous(name="Proportion of word") + scale_x_discrete(name="Top 20 most frequent words of Star 4") + theme(axis.text.y = element_text(hjust = 1, size = 8, face = "bold"))
#5 star rating
star5 <- table2 %>% filter(stars=='5') %>% arrange(desc(prop))
ggplot(star5, aes(x=star5$word, y=star5$prop, fill=star5$word)) + geom_bar(stat="identity") + coord_flip() + scale_y_continuous(name="Proportion of word") + scale_x_discrete(name="Top 20 most frequent words of Star 5") + theme(axis.text.y = element_text(hjust = 1, size = 8, face = "bold"))

#check the proportion of 'food' among reviews with 1,2,..5 stars 
a <- ws %>% filter(word=='food')
write.csv(a, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/a.csv")
ggplot(a, aes(x=a$stars, y=a$prop)) + geom_bar(stat = "identity", fill=a$stars, width = 0.5) + coord_flip() + scale_y_continuous(name = "Proportion of Food") + scale_x_continuous(name = "Star rating")

#check the proportion of 'time' among reviews with 1,2,..5 stars 
b <- ws %>% filter(word=='time')
write.csv(b, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/b.csv")
ggplot(b, aes(x=b$stars, y=b$prop)) + geom_bar(stat = "identity", fill=b$stars, width = 0.5) + coord_flip() + scale_y_continuous(name = "Proportion of Time") + scale_x_continuous(name = "Star rating")

#check the proportion of 'service' among reviews with 1,2,..5 stars 
c <- ws %>% filter(word=='service')
write.csv(c, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/c.csv")
ggplot(c, aes(x=c$stars, y=c$prop)) + geom_bar(stat = "identity", fill=c$stars, width = 0.5) + coord_flip() + scale_y_continuous(name = "Proportion of Service") + scale_x_continuous(name = "Star rating")

#check the proportion of 'eat' among reviews with 1,2,..5 stars 
d <- ws %>% filter(word=='eat')
write.csv(d, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/d.csv")
ggplot(d, aes(x=d$stars, y=d$prop)) + geom_bar(stat = "identity", fill=d$stars, width = 0.5) + coord_flip() + scale_y_continuous(name = "Proportion of Eat") + scale_x_continuous(name = "Star rating")

#check the proportion of 'restaurant' among reviews with 1,2,..5 stars 
e <- ws %>% filter(word=='restaurant')
write.csv(e, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/e.csv")
ggplot(e, aes(x=e$stars, y=e$prop)) + geom_bar(stat = "identity", fill=e$stars, width = 0.5) + coord_flip() + scale_y_continuous(name = "Proportion of Restaurant") + scale_x_continuous(name = "Star rating")

#check the proportion of 'chicken' among reviews with 1,2,..5 stars 
f <- ws %>% filter(word=='chicken')
write.csv(f, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/f.csv")
ggplot(f, aes(x=f$stars, y=f$prop)) + geom_bar(stat = "identity", fill=f$stars, width = 0.5) + coord_flip() + scale_y_continuous(name = "Proportion of Chicken") + scale_x_continuous(name = "Star rating")

#check the proportion of 'pizza' among reviews with 1,2,..5 stars 
g <- ws %>% filter(word=='pizza')
write.csv(g, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/g.csv")
ggplot(g, aes(x=g$stars, y=g$prop)) + geom_bar(stat = "identity", fill=g$stars, width = 0.5) + coord_flip() + scale_y_continuous(name = "Proportion of Pizza") + scale_x_continuous(name = "Star rating")

#check the proportion of 'taste' among reviews with 1,2,..5 stars 
h <- ws %>% filter(word=='taste')
write.csv(h, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/h.csv")
ggplot(h, aes(x=h$stars, y=h$prop)) + geom_bar(stat = "identity", fill=h$stars, width = 0.5) + coord_flip() + scale_y_continuous(name = "Proportion of Taste") + scale_x_continuous(name = "Star rating")

#check the proportion of 'price' among reviews with 1,2,..5 stars 
i <- ws %>% filter(word=='price')
write.csv(i, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/i.csv")
ggplot(i, aes(x=i$stars, y=i$prop)) + geom_bar(stat = "identity", fill=i$stars, width = 0.5) + coord_flip() + scale_y_continuous(name = "Proportion of Price") + scale_x_continuous(name = "Star rating")

#check the proportion of 'sauce' among reviews with 1,2,..5 stars 
j <- ws %>% filter(word=='sauce')
write.csv(j, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/j.csv")
ggplot(j, aes(x=j$stars, y=j$prop)) + geom_bar(stat = "identity", fill=j$stars, width = 0.5) + coord_flip() + scale_y_continuous(name = "Proportion of Sauce") + scale_x_continuous(name = "Star rating")

#check the proportion of 'fry' among reviews with 1,2,..5 stars 
k <- ws %>% filter(word=='fry')
write.csv(k, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/k.csv")
ggplot(k, aes(x=k$stars, y=k$prop)) + geom_bar(stat = "identity", fill=k$stars, width = 0.5) + coord_flip() + scale_y_continuous(name = "Proportion of Fry") + scale_x_continuous(name = "Star rating")

#check the proportion of 'menu' among reviews with 1,2,..5 stars 
l <- ws %>% filter(word=='menu')
write.csv(l, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/l.csv")
ggplot(l, aes(x=l$stars, y=l$prop)) + geom_bar(stat = "identity", fill=l$stars, width = 0.5) + coord_flip() + scale_y_continuous(name = "Proportion of Menu") + scale_x_continuous(name = "Star rating")

#check the proportion of 'nice' among reviews with 1,2,..5 stars 
m <- ws %>% filter(word=='nice')
write.csv(m, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/m.csv")
ggplot(m, aes(x=m$stars, y=m$prop)) + geom_bar(stat = "identity", fill=m$stars, width = 0.5) + coord_flip() + scale_y_continuous(name = "Proportion of Nice") + scale_x_continuous(name = "Star rating")

#removing very high frequency words that have similar proportion across all ratings
rem <- rrTokens %>% filter(word=='food' | word=='time' | word=='service' | word=='eat' | word=='restaurant' | word=='chicken' | word=='pizza' | word=='price' | word=='sauce' | word=='fry' | word=='menu' | word=='taste')
rrTokens <- anti_join(rrTokens, rem)
#Dimensions for rrTokens
rrTokens %>% dim()
#dimension for distinct words after removing rare words
rrTokens %>% distinct(word) %>% dim()

#Finding words indicative of positive and negative sentiment 
#(average star rating of a word approach)
ws<-rrTokens %>% group_by(stars) %>% count(word, sort=TRUE)
ws<-ws %>% group_by(stars) %>% mutate(prop=n/sum(n)) %>% arrange(desc(stars, prop))
xx<- ws %>% group_by(word) %>% summarise(totWS=sum(stars*prop)) %>% arrange(desc(totWS))

gtop_20    <- xx %>% top_n(20)
write.csv(gtop_20, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/gtop_20.csv")
ggplot(gtop_20, aes(x=gtop_20$word, y=gtop_20$totWS, fill=gtop_20$word)) + geom_bar(stat = "identity", width = 0.5) + coord_flip() + scale_y_continuous(name = "Average Star Rating") + scale_x_discrete(name = "Words")

gbottom_20 <- xx %>% top_n(-20)
write.csv(gbottom_20, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/gbottom_20.csv")
ggplot(gbottom_20, aes(x=gbottom_20$word, y=gbottom_20$totWS, fill=gbottom_20$word)) + geom_bar(stat = "identity", width = 0.5) + coord_flip() + scale_y_continuous(name = "Average Star Rating") + scale_x_discrete(name = "Words")

#make a copy of rrTokens
rrTokens1 <- rrTokens

#calculate tf, idf and tf-idf
rrTokens <- rrTokens %>% group_by(review_id, stars) %>% count(word)
rrTokens <- rrTokens %>% bind_tf_idf(word, review_id, n)

#ungroup rrTokens
rrTokens <- ungroup(rrTokens)
```

#Q-3
# #######################
#Part (c) - Sentiment Prediction
# #######################
```{r}
#quick look at the dictionaries that we will be using
get_sentiments("bing") %>% view()
get_sentiments("nrc") %>% view()
get_sentiments("afinn") %>% view()

# ################### Bing Dictionary ####################
# ################### Inner Join      ####################

#get the sentiment of words in rrTokens from Bing
rrSenti_bing<- rrTokens %>% inner_join(get_sentiments("bing"), by="word")
#Dimensions for rrSenti_bing
rrSenti_bing %>% dim()
#dimension for distinct words after performing inner join with Bing
rrSenti_bing %>% distinct(word) %>% dim()

#count the total occurence of words
xx<-rrSenti_bing %>% group_by(word, sentiment) %>% summarise(totOcc=sum(n)) %>% arrange(sentiment, desc(totOcc))

#word count and word occurence for different sentiment categories
xx1 <- xx %>% group_by(sentiment) %>% summarise(count=n(), sumn=sum(totOcc))
write.csv(xx1, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/xx1.csv")

#negate count for negative sentiment words
xx<- xx %>% mutate (totOcc=ifelse(sentiment=="positive", totOcc, -totOcc))

#Ungroup xx
xx<-ungroup(xx)

#top 25 positive words based on total occurence 
bingPos_25 <- xx %>% top_n(25)
write.csv(bingPos_25, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/bingPos_25.csv")

#top 25 negative words based on total occurence
bingNeg_25 <- xx %>% top_n(-25)
write.csv(bingNeg_25, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/bingNeg_25.csv")

#plot for positive and negative words
temp <- rbind(top_n(xx, 25), top_n(xx, -25)) %>% mutate(word=reorder(word,totOcc))
ggplot(temp, aes(word, totOcc, fill=sentiment)) +geom_col(color="#FFFFFF")+coord_flip() + scale_y_continuous(name = "Total Occurence") + scale_x_discrete(name = "Words") + theme(axis.text.y = element_text(hjust = 1, face = "bold", size = 8))

#summarise number of positive/negative sentiment words per review
revSenti_bing <- rrSenti_bing %>% group_by(review_id, stars) %>% summarise(nwords=n(),posSum=sum(sentiment=='positive'), negSum=sum(sentiment=='negative'))

#summarise positive/negative sentiment words proportion per review
revSenti_bing<- revSenti_bing %>% mutate(posProp=posSum/nwords, negProp=negSum/nwords)

#calculate sentiment score
revSenti_bing<- revSenti_bing %>% mutate(sentiScore=posProp-negProp)

#calculate average sentiment score for each rating
bing_star_table <- revSenti_bing %>% group_by(stars) %>% summarise(avgPos=mean(posProp), avgNeg=mean(negProp), avgSentiSc=mean(sentiScore))
write.csv(bing_star_table, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/bing_star_table.csv")
ggplot(bing_star_table, aes(bing_star_table$stars, bing_star_table$avgSentiSc)) + geom_bar(stat = "identity", width = 0.5, fill=bing_star_table$stars) + coord_flip() + scale_y_continuous(name = "Average Sentiment Score") + scale_x_continuous(name = "Star Rating") + theme(axis.text.y = element_text(hjust = 1, size = 8, face = "bold"))

# Assign -1  for 1 and 2 star rating
# Assign  0  for 3 star rating
# Assign  1  for 4 and 5 star rating
revSenti_bing <- revSenti_bing %>% mutate(hiLo=ifelse(stars<=2,-1, ifelse(stars>=4, 1, 0 )))
revSenti_bing <- revSenti_bing %>% mutate(pred_hiLo=ifelse(sentiScore >0, 1, -1))

#filter out the reviews with 3 stars, and get the confusion matrix for hiLo vs pred_hiLo
final<-revSenti_bing %>% filter(hiLo!=0)
cm <- table(actual=final$hiLo, predicted=final$pred_hiLo)
write.csv(cm, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/cm.csv")

# ################### NRC Dictionary ####################
# ################### Inner Join      ####################

#get the sentiment of words in rrTokens from NRC
rrSenti_nrc<-rrTokens %>% inner_join(get_sentiments("nrc"), by="word")
#Dimensions for rrSenti_nrc
rrSenti_nrc %>% dim()
#dimension for distinct words after performing inner join with NRC
rrSenti_nrc %>% distinct(word) %>% dim()

#count the total occurence of words
xx<-rrSenti_nrc %>% group_by(word, sentiment) %>% summarise(totOcc=sum(n)) %>% arrange(sentiment, desc(totOcc))

#word count and word occurence for different sentiment categories
xx1 <- xx %>% group_by(sentiment) %>% summarise(count=n(), sumn=sum(totOcc))
write.csv(xx1, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/xx1.csv")

#check for words denoting different sentiment
rrSenti_nrc %>% filter(sentiment=='anger') %>% view()
rrSenti_nrc %>% filter(sentiment=='anticipation') %>% view()
rrSenti_nrc %>% filter(sentiment=='disgust') %>% view()
rrSenti_nrc %>% filter(sentiment=='fear') %>% view()
rrSenti_nrc %>% filter(sentiment=='joy') %>% view()
rrSenti_nrc %>% filter(sentiment=='negative') %>% view()
rrSenti_nrc %>% filter(sentiment=='positive') %>% view()
rrSenti_nrc %>% filter(sentiment=='sadness') %>% view()
rrSenti_nrc %>% filter(sentiment=='surprise') %>% view()
rrSenti_nrc %>% filter(sentiment=='trust') %>% view()

#consider {anticipation, joy, positive, surprise, trust} as positive reviews (Positive totOcc)
#consider {anger, disgust, fear, negative, sadness} as negative reviews      (Negative totOcc)
xx<-xx %>% mutate(totOcc=ifelse(sentiment %in% c('anger', 'disgust', 'fear', 'negative', 'sadness'), -totOcc, ifelse(sentiment %in% c('anticipation', 'joy', 'positive', 'surprise', 'trust'), totOcc, 0)))

#classify into only 2 categories (positive and negative) based on totOcc
xx<-xx %>% mutate(posNeg=ifelse(totOcc >0, 'positive', 'negative'))

#Ungroup xx
xx<-ungroup(xx)

#top 25 positive words based on total occurence 
NRCPos_25 <- xx %>% distinct(word, totOcc, posNeg) %>% top_n(n=25, wt=totOcc)
write.csv(NRCPos_25, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/NRCPos_25.csv")

#top 25 negative words based on total occurence
NRCNeg_25 <- xx %>% distinct(word, totOcc, posNeg) %>% top_n(n=(-25), wt=totOcc)
write.csv(NRCNeg_25, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/NRCNeg_25.csv")

#plot for positive and negative words
temp <- rbind(NRCPos_25, NRCNeg_25) %>% mutate(word=reorder(word,totOcc))
ggplot(temp, aes(word, totOcc, fill=posNeg)) +geom_col(color="#FFFFFF")+coord_flip() + scale_y_continuous(name = "Total Occurence") + scale_x_discrete(name = "Words") + theme(axis.text.y = element_text(hjust = 1, face = "bold", size = 8))

#summarise number of positive/negative sentiment words per review
revSenti_nrc <- rrSenti_nrc %>% group_by(review_id, stars) %>% summarise(nwords=n(),posSum=sum(sentiment %in% c('anticipation', 'joy', 'positive', 'surprise', 'trust')), negSum=sum(sentiment %in% c('anger', 'disgust', 'fear', 'negative', 'sadness')))

#summarise positive/negative sentiment words proportion per review
revSenti_nrc<- revSenti_nrc %>% mutate(posProp=posSum/nwords, negProp=negSum/nwords)

#calculate sentiment score
revSenti_nrc<- revSenti_nrc %>% mutate(sentiScore=posProp-negProp)

#calculate average sentiment score for each rating
nrc_star_table <- revSenti_nrc %>% group_by(stars) %>% summarise(avgPos=mean(posProp), avgNeg=mean(negProp), avgSentiSc=mean(sentiScore))
write.csv(nrc_star_table, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/nrc_star_table.csv")
ggplot(nrc_star_table, aes(nrc_star_table$stars, nrc_star_table$avgSentiSc)) + geom_bar(stat = "identity", width = 0.5, fill=nrc_star_table$stars) + coord_flip() + scale_y_continuous(name = "Average Sentiment Score") + scale_x_continuous(name = "Star Rating") + theme(axis.text.y = element_text(hjust = 1, size = 8, face = "bold"))

# Assign -1  for 1 and 2 star rating
# Assign  0  for 3 star rating
# Assign  1  for 4 and 5 star rating
revSenti_nrc <- revSenti_nrc %>% mutate(hiLo=ifelse(stars<=2,-1, ifelse(stars>=4, 1, 0 )))
revSenti_nrc <- revSenti_nrc %>% mutate(pred_hiLo=ifelse(sentiScore >0, 1, -1))

#filter out the reviews with 3 stars, and get the confusion matrix for hiLo vs pred_hiLo
final<-revSenti_nrc %>% filter(hiLo!=0)
cm <- table(actual=final$hiLo, predicted=final$pred_hiLo)
write.csv(cm, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/cm.csv")

# ################### Afinn Dictionary ####################
# ################### Inner Join       ####################

#get the sentiment of words in rrTokens from Afinn
rrSenti_afinn<- rrTokens %>% inner_join(get_sentiments("afinn"), by="word")
#Dimensions for rrSenti_afinn
rrSenti_afinn %>% dim()
#dimension for distinct words after performing inner join with Afinn
rrSenti_afinn %>% distinct(word) %>% dim()

#count the total occurence of words
xx<-rrSenti_afinn %>% group_by(word, value) %>% summarise(totOcc=sum(n)) %>% arrange(value, desc(totOcc))

#word count and word occurence for different sentiment categories
xx1 <- xx %>% group_by(value) %>% summarise(count=n(), sumn=sum(totOcc))
write.csv(xx1, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/xx1.csv")

#negate count for negative sentiment words (based on value)
xx<- xx %>% mutate (totOcc=ifelse(value>0, totOcc, -totOcc))

#classify into only 2 categories (positive and negative) based on totOcc
xx<-xx %>% mutate(posNeg=ifelse(totOcc >0, 'positive', 'negative'))

#Ungroup xx
xx<-ungroup(xx)

#top 25 positive words based on total occurence 
afinnPos_25 <- xx %>% top_n(n=25, wt=totOcc)
write.csv(afinnPos_25, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/afinnPos_25.csv")

#top 25 negative words based on total occurence
afinnNeg_25 <- xx %>% top_n(n=-25, wt=totOcc)
write.csv(afinnNeg_25, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/afinnNeg_25.csv")

#plot for positive and negative words
temp <- rbind(afinnPos_25, afinnNeg_25) %>% mutate(word=reorder(word,totOcc))
ggplot(temp, aes(word, totOcc, fill=posNeg)) +geom_col(color="#FFFFFF")+coord_flip() + scale_y_continuous(name = "Total Occurence") + scale_x_discrete(name = "Words") + theme(axis.text.y = element_text(hjust = 1, face = "bold", size = 8))

#summarise number of positive/negative sentiment words per review
revSenti_afinn <- rrSenti_afinn %>% group_by(review_id, stars) %>% summarise(nwords=n(),posSum=sum(value>0), negSum=sum(value<0))

#summarise positive/negative sentiment words proportion per review
revSenti_afinn<- revSenti_afinn %>% mutate(posProp=posSum/nwords, negProp=negSum/nwords)

#calculate sentiment score
revSenti_afinn<- revSenti_afinn %>% mutate(sentiScore=posProp-negProp)

#calculate average sentiment score for each rating
afinn_star_table <- revSenti_afinn %>% group_by(stars) %>% summarise(avgPos=mean(posProp), avgNeg=mean(negProp), avgSentiSc=mean(sentiScore))
write.csv(afinn_star_table, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/afinn_star_table.csv")
ggplot(afinn_star_table, aes(afinn_star_table$stars, afinn_star_table$avgSentiSc)) + geom_bar(stat = "identity", width = 0.5, fill=afinn_star_table$stars) + coord_flip() + scale_y_continuous(name = "Average Sentiment Score") + scale_x_continuous(name = "Star Rating") + theme(axis.text.y = element_text(hjust = 1, size = 8, face = "bold"))

# Assign -1  for 1 and 2 star rating
# Assign  0  for 3 star rating
# Assign  1  for 4 and 5 star rating
revSenti_afinn <- revSenti_afinn %>% mutate(hiLo=ifelse(stars<=2,-1, ifelse(stars>=4, 1, 0 )))
revSenti_afinn <- revSenti_afinn %>% mutate(pred_hiLo=ifelse(sentiScore >0, 1, -1))

#filter out the reviews with 3 stars, and get the confusion matrix for hiLo vs pred_hiLo
final<-revSenti_afinn %>% filter(hiLo!=0)
cm <- table(actual=final$hiLo, predicted=final$pred_hiLo)
write.csv(cm, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/cm.csv")
```

#Q 4-(a)
# #######################
#Part (d) - Model Creation
# #######################

# #######################################################
# Subpart (i) - Models on words that match the dictionary
# #######################################################

# ###################     Bing      ####################
```{r}
#create Document Term Matrix
revDTM_sentiBing <- rrSenti_bing %>%  pivot_wider(id_cols = c(review_id,stars), names_from = word, values_from = tf_idf)  %>% ungroup()

#Dimensions for revDTM_sentiBing
revDTM_sentiBing %>% dim()

#filter out the reviews with stars=3
#calculate hiLo sentiment(1 is assigned to 4 and 5/-1 is assigned to 1 and 2)
revDTM_sentiBing <- revDTM_sentiBing %>% filter(stars!=3) %>% mutate(hiLo=ifelse(stars<=2, -1, 1)) %>% select(-stars)

#Dimensions for revDTM_sentiBing
revDTM_sentiBing %>% dim()

#replace all NAs with zero
revDTM_sentiBing<-revDTM_sentiBing %>% replace(., is.na(.), 0)

#convert hiLo from num to factor
revDTM_sentiBing$hiLo<- as.factor(revDTM_sentiBing$hiLo)

#no of reviews with 1, -1 class
Bing_hiLo_count <- revDTM_sentiBing %>% group_by(hiLo) %>% tally()
write.csv(Bing_hiLo_count, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/Bing_hiLo_count.csv")

set.seed(1234)

#split the data into training and test dataset (50:50)
revDTM_sentiBing_split<- initial_split(revDTM_sentiBing, 0.5)
revDTM_sentiBing_trn  <- training(revDTM_sentiBing_split)
revDTM_sentiBing_tst  <- testing(revDTM_sentiBing_split)
```

#RF Model
```{r}
rfModel1<-ranger(dependent.variable.name = "hiLo", data=revDTM_sentiBing_trn %>% select(-review_id), num.trees = 500, importance='permutation', probability = TRUE)

#Make predictions from the model on trn and test dataset
revSentiBing_predTrn<- predict(rfModel1, revDTM_sentiBing_trn %>% select(-review_id))
revSentiBing_predTst<- predict(rfModel1, revDTM_sentiBing_tst %>% select(-review_id))

#find the optimal TH
rocTrn <- roc(revDTM_sentiBing_trn$hiLo, revSentiBing_predTrn$predictions[,2], levels=c(-1, 1))
rocTst <- roc(revDTM_sentiBing_tst$hiLo, revSentiBing_predTst$predictions[,2], levels=c(-1, 1))

plot.roc(rocTrn, col='blue', legacy.axes = TRUE)
plot.roc(rocTst, col='red', add=TRUE)
legend("bottomright", legend=c("Training", "Test"),
        col=c("blue", "red"), lwd=2, cex=0.8, bty='n')

#best threshold from ROC
bThr<-coords(rocTrn, "best", ret="threshold", transpose = FALSE)
bThr <- as.numeric(bThr)

#Confusion Matrix at bThr for Trn and Tst dataset
a <- table(actual=revDTM_sentiBing_trn$hiLo, preds=revSentiBing_predTrn$predictions[,2]>bThr)
b <- table(actual=revDTM_sentiBing_tst$hiLo, preds=revSentiBing_predTst$predictions[,2]>bThr)

write.csv(a, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/bthr_trn.csv")
write.csv(b, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/bthr_tst.csv")

#Confusion Matrix at 0.5 for Trn and Tst dataset
c <- table(actual=revDTM_sentiBing_trn$hiLo, preds=revSentiBing_predTrn$predictions[,2]>0.5)
d <- table(actual=revDTM_sentiBing_tst$hiLo, preds=revSentiBing_predTst$predictions[,2]>0.5)

write.csv(c, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/0.5_trn.csv")
write.csv(d, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/0.5_tst.csv")
```

#SVM Bing Dictionary
```{r}
library("e1071")
library("ROCR")
#model 1
system.time( svmBing1 <- svm(as.factor(hiLo) ~., data = revDTM_sentiBing_trn
%>% select(-review_id), kernel="radial", cost=1, gamma=2, scale=FALSE, decision.values = TRUE)) 

revDTM_predTrn_svmBing1<-predict(svmBing1, revDTM_sentiBing_trn, decision.values = TRUE)
table(actual= revDTM_sentiBing_trn$hiLo, predicted= revDTM_predTrn_svmBing1)
revDTM_predTst_svmBing1<-predict(svmBing1, revDTM_sentiBing_tst, decision.values = TRUE)
table(actual= revDTM_sentiBing_tst$hiLo, predicted= revDTM_predTst_svmBing1)

svmtrn.roc <- prediction(attributes(revDTM_predTrn_svmBing1)$decision.values, revDTM_sentiBing_trn$hiLo)
svmtrn.auc <- performance(svmtrn.roc, 'tpr', 'fpr')
aucsvmtrn <- performance(svmtrn.roc, 'auc')

auc(as.numeric(revDTM_sentiBing_trn$hiLo), as.numeric(revDTM_predTrn_svmBing1))

svmtst.roc <- prediction(attributes(revDTM_predTst_svmBing1)$decision.values, revDTM_sentiBing_tst$hiLo)
svmtst.auc <- performance(svmtst.roc, 'tpr', 'fpr')
aucsvmtst <- performance(svmtst.roc, 'auc')

auc(as.numeric(revDTM_sentiBing_tst$hiLo), as.numeric(revDTM_predTst_svmBing1))

plot(svmtrn.auc, col='green', add = TRUE, legacy.axes = TRUE)
plot(svmtst.auc, col='red', add=TRUE)
legend("bottomright", legend=c("Training", "Test"),
        col=c("green", "red"), lwd=2, cex=0.8, bty='n')
abline(a = 0, b = 1)

#model 2
system.time( svmBing2 <- svm(as.factor(hiLo) ~., data = revDTM_sentiBing_trn
%>% select(-review_id), kernel="radial", cost=10, gamma=0.5, scale=FALSE, decision.values = TRUE)) 

revDTM_predTrn_svmBing2<-predict(svmBing2, revDTM_sentiBing_trn, decision.values = TRUE)
table(actual= revDTM_sentiBing_trn$hiLo, predicted= revDTM_predTrn_svmBing2)
revDTM_predTst_svmBing2<-predict(svmBing2, revDTM_sentiBing_tst, decision.values = TRUE)
table(actual= revDTM_sentiBing_tst$hiLo, predicted= revDTM_predTst_svmBing2)

svmtrn.roc <- prediction(attributes(revDTM_predTrn_svmBing2)$decision.values, revDTM_sentiBing_trn$hiLo)
svm2trn.auc <- performance(svmtrn.roc, 'tpr', 'fpr')
aucsvmtrn2 <- performance(svmtrn.roc, 'auc')
auc(as.numeric(revDTM_sentiBing_trn$hiLo), as.numeric(revDTM_predTrn_svmBing2))


svmtst.roc <- prediction(attributes(revDTM_predTst_svmBing2)$decision.values, revDTM_sentiBing_tst$hiLo)
svm2tst.auc <- performance(svmtst.roc, 'tpr', 'fpr')
aucsvmtst2 <- performance(svmtst.roc, 'auc')
aucsvmtst2
auc(as.numeric(revDTM_sentiBing_tst$hiLo), as.numeric(revDTM_predTst_svmBing2))


#ROC plot
plot(svm2trn.auc)
plot(svm2trn.auc, col='green', add = TRUE, legacy.axes = TRUE)
plot(svm2tst.auc, col='red', add=TRUE)
legend("bottomright", legend=c("Training", "Test"),
        col=c("green", "red"), lwd=2, cex=0.8, bty='n')
abline(a = 0, b = 1)

#Model 3

system.time( svmBing3 <- svm(as.factor(hiLo) ~., data = revDTM_sentiBing_trn
%>% select(-review_id), kernel="radial", cost=10, gamma=1, scale=FALSE, decision.values = TRUE)) 

revDTM_predTrn_svmBing3<-predict(svmBing3, revDTM_sentiBing_trn, decision.values = TRUE)
table(actual= revDTM_sentiBing_trn$hiLo, predicted= revDTM_predTrn_svmBing3)
revDTM_predTst_svmBing3<-predict(svmBing3, revDTM_sentiBing_tst, decision.values = TRUE)
table(actual= revDTM_sentiBing_tst$hiLo, predicted= revDTM_predTst_svmBing3)

svmtrn.roc <- prediction(attributes(revDTM_predTrn_svmBing3)$decision.values, revDTM_sentiBing_trn$hiLo)
svm3trn.auc <- performance(svmtrn.roc, 'tpr', 'fpr')
aucsvmtrn <- performance(svmtrn.roc, 'auc')
auc(as.numeric(revDTM_sentiBing_trn$hiLo), as.numeric(revDTM_predTrn_svmBing3))

svmtst.roc <- prediction(attributes(revDTM_predTst_svmBing3)$decision.values, revDTM_sentiBing_tst$hiLo)
svm3tst.auc <- performance(svmtst.roc, 'tpr', 'fpr')
aucsvmtst <- performance(svmtst.roc, 'auc')
auc(as.numeric(revDTM_sentiBing_tst$hiLo), as.numeric(revDTM_predTst_svmBing3))

#ROC plot
plot(svm3trn.auc)
plot(svm3trn.auc, col='green', add = TRUE, legacy.axes = TRUE)
plot(svm3tst.auc, col='red', add=TRUE)
legend("bottomright", legend=c("Training", "Test"),
        col=c("green", "red"), lwd=2, cex=0.8, bty='n')
abline(a = 0, b = 1)

#Model 4

system.time( svmBing4 <- svm(as.factor(hiLo) ~., data = revDTM_sentiBing_trn
%>% select(-review_id), kernel="radial", cost=50, gamma=1, scale=FALSE, decision.values = TRUE)) 

revDTM_predTrn_svmBing4<-predict(svmBing4, revDTM_sentiBing_trn, decision.values = TRUE)
table(actual= revDTM_sentiBing_trn$hiLo, predicted= revDTM_predTrn_svmBing4)
revDTM_predTst_svmBing4<-predict(svmBing4, revDTM_sentiBing_tst, decision.values = TRUE)
table(actual= revDTM_sentiBing_tst$hiLo, predicted= revDTM_predTst_svmBing4)

svmtrn.roc <- prediction(attributes(revDTM_predTrn_svmBing4)$decision.values, revDTM_sentiBing_trn$hiLo)
svm4trn.auc <- performance(svmtrn.roc, 'tpr', 'fpr')
aucsvmtrn <- performance(svmtrn.roc, 'auc')
auc(as.numeric(revDTM_sentiBing_trn$hiLo), as.numeric(revDTM_predTrn_svmBing4))


svmtst.roc <- prediction(attributes(revDTM_predTst_svmBing4)$decision.values, revDTM_sentiBing_tst$hiLo)
svm4tst.auc <- performance(svmtst.roc, 'tpr', 'fpr')
aucsvmtst <- performance(svmtst.roc, 'auc')
auc(as.numeric(revDTM_sentiBing_tst$hiLo), as.numeric(revDTM_predTst_svmBing4))

#ROC plot
plot(svm4trn.auc)
plot(svm4trn.auc, col='green', add = TRUE, legacy.axes = TRUE)
plot(svm4tst.auc, col='red', add=TRUE)
legend("bottomright", legend=c("Training", "Test"),
        col=c("green", "red"), lwd=2, cex=0.8, bty='n')
abline(a = 0, b = 1)

```

#Naive Bayes
```{r message=FALSE, cache=TRUE}

library(pROC)
library(e1071)

#model 1a - without laplace
nbModel1<-naiveBayes(hiLo ~ ., data=revDTM_sentiBing_trn %>% select(-review_id))

#training data
revSentiBing_NBpredTrn<-predict(nbModel1, revDTM_sentiBing_trn, type = "raw")
cmtrn1 <- table(actual=revDTM_sentiBing_trn$hiLo, preds=revSentiBing_NBpredTrn[,2]>0.5)
#52.8%

#test data
revSentiBing_NBpredTst<-predict(nbModel1, revDTM_sentiBing_tst, type = "raw")
cmtst1 <- table(actual=revDTM_sentiBing_tst$hiLo, preds=revSentiBing_NBpredTst[,2]>0.5)
#52.78%

#AUC values
auc(as.numeric(revDTM_sentiBing_trn$hiLo), revSentiBing_NBpredTrn[,2]) #69.77

auc(as.numeric(revDTM_sentiBing_tst$hiLo), revSentiBing_NBpredTst[,2]) #71.49


#model 1b - with laplace
nbModel1<-naiveBayes(hiLo ~ ., data=revDTM_sentiBing_trn %>% select(-review_id), laplace = 2)

#training data
revSentiBing_NBpredTrn<-predict(nbModel1, revDTM_sentiBing_trn, type = "raw")
cmtrn1 <- table(actual=revDTM_sentiBing_trn$hiLo, preds=revSentiBing_NBpredTrn[,2]>0.5)

#test data
revSentiBing_NBpredTst<-predict(nbModel1, revDTM_sentiBing_tst, type = "raw")
cmtst1 <- table(actual=revDTM_sentiBing_tst$hiLo, preds=revSentiBing_NBpredTst[,2]>0.5)


auc(as.numeric(revDTM_sentiBing_trn$hiLo), revSentiBing_NBpredTrn[,2])
auc(as.numeric(revDTM_sentiBing_tst$hiLo), revSentiBing_NBpredTst[,2])

```


# ###################     Nrc      ####################
```{r}
#make a copy of rrSenti_nrc
rrSenti_nrc1 <- rrSenti_nrc

#remove duplicates from rrSenti_nrc
rrSenti_nrc <-rrSenti_nrc[,-8]
rrSenti_nrc <-rrSenti_nrc[!duplicated(rrSenti_nrc), ]

#Dimensions for rrSenti_nrc 
rrSenti_nrc %>% dim()

#Dimensions for the distinct word tokens in rrSenti_nrc
rrSenti_nrc %>% distinct(word) %>% dim()

#create Document Term Matrix
revDTM_sentiNrc <- rrSenti_nrc %>%  pivot_wider(id_cols = c(review_id,stars), names_from = word, values_from = tf_idf)  %>% ungroup()

#Dimensions for revDTM_sentiNrc
revDTM_sentiNrc %>% dim()

#filter out the reviews with stars=3
#calculate hiLo sentiment(1 is assigned to 4 and 5/-1 is assigned to 1 and 2)
revDTM_sentiNrc <- revDTM_sentiNrc %>% filter(stars!=3) %>% mutate(hiLo=ifelse(stars<=2, -1, 1)) %>% select(-stars)

#Dimensions for revDTM_sentiNrc
revDTM_sentiNrc %>% dim()

#replace all NAs with zero
revDTM_sentiNrc<-revDTM_sentiNrc %>% replace(., is.na(.), 0)

#convert hiLo from num to factor
revDTM_sentiNrc$hiLo<- as.factor(revDTM_sentiNrc$hiLo)

#no of reviews with 1, -1 class
Nrc_hiLo_count <- revDTM_sentiNrc %>% group_by(hiLo) %>% tally()
write.csv(Nrc_hiLo_count, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/Nrc_hiLo_count.csv")

set.seed(1234)

#split the data into training and test dataset (50:50)
revDTM_sentiNrc_split<- initial_split(revDTM_sentiNrc, 0.5)
revDTM_sentiNrc_trn  <- training(revDTM_sentiNrc_split)
revDTM_sentiNrc_tst  <- testing(revDTM_sentiNrc_split)
```

#RF Model for NRC
```{r}
#RF Model
rfModel1<-ranger(dependent.variable.name = "hiLo", data=revDTM_sentiNrc_trn %>% select(-review_id), num.trees = 500, importance='permutation', probability = TRUE)

#Make predictions from the model on trn and test dataset
revSentiNrc_predTrn<- predict(rfModel1, revDTM_sentiNrc_trn %>% select(-review_id))
revSentiNrc_predTst<- predict(rfModel1, revDTM_sentiNrc_tst %>% select(-review_id))

#find the optimal TH
rocTrn <- roc(revDTM_sentiNrc_trn$hiLo, revSentiNrc_predTrn$predictions[,2], levels=c(-1, 1))
rocTst <- roc(revDTM_sentiNrc_tst$hiLo, revSentiNrc_predTst$predictions[,2], levels=c(-1, 1))

plot.roc(rocTrn, col='blue', legacy.axes = TRUE)
plot.roc(rocTst, col='red', add=TRUE)
legend("bottomright", legend=c("Training", "Test"),
        col=c("blue", "red"), lwd=2, cex=0.8, bty='n')

#best threshold from ROC
bThr<-coords(rocTrn, "best", ret="threshold", transpose = FALSE)
bThr <- as.numeric(bThr)

#Confusion Matrix at bThr for Trn and Tst dataset
a <- table(actual=revDTM_sentiNrc_trn$hiLo, preds=revSentiNrc_predTrn$predictions[,2]>bThr)
b <- table(actual=revDTM_sentiNrc_tst$hiLo, preds=revSentiNrc_predTst$predictions[,2]>bThr)

write.csv(a, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/bthr_trn.csv")
write.csv(b, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/bthr_tst.csv")

#Confusion Matrix at 0.5 for Trn and Tst dataset
c <- table(actual=revDTM_sentiNrc_trn$hiLo, preds=revSentiNrc_predTrn$predictions[,2]>0.5)
d <- table(actual=revDTM_sentiNrc_tst$hiLo, preds=revSentiNrc_predTst$predictions[,2]>0.5)

write.csv(c, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/0.5_trn.csv")
write.csv(d, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/0.5_tst.csv")
```

#SVM Model for NRC
```{r}
#model 1
system.time( svmNRC1 <- svm(as.factor(hiLo) ~., data = revDTM_sentiNrc_trn
%>% select(-review_id), kernel="radial", cost=50, gamma=1, scale=FALSE, decision.values = TRUE)) 

revDTM_predTrn_svmNRC1<-predict(svmNRC1, revDTM_sentiNrc_trn, decision.values = TRUE)
table(actual= revDTM_sentiNrc_trn$hiLo, predicted= revDTM_predTrn_svmNRC1)
revDTM_predTst_svmNRC1<-predict(svmNRC1, revDTM_sentiNrc_tst, decision.values = TRUE)
table(actual= revDTM_sentiNrc_tst$hiLo, predicted= revDTM_predTst_svmNRC1)

svmtrn.roc <- prediction(attributes(revDTM_predTrn_svmNRC1)$decision.values, revDTM_sentiNrc_trn$hiLo)
svmtrn.auc <- performance(svmtrn.roc, 'tpr', 'fpr')
aucsvmtrn <- performance(svmtrn.roc, 'auc')

svmtst.roc <- prediction(attributes(revDTM_predTst_svmNRC1)$decision.values, revDTM_sentiNrc_tst$hiLo)
svmtst.auc <- performance(svmtst.roc, 'tpr', 'fpr')
aucsvmtst <- performance(svmtst.roc, 'auc')


auc(as.numeric(revDTM_sentiNrc_trn$hiLo), as.numeric(revDTM_predTrn_svmNRC1))

auc(as.numeric(revDTM_sentiNrc_tst$hiLo), as.numeric(revDTM_predTst_svmNRC1))

plot(svmtrn.auc, col='green', add = TRUE, legacy.axes = TRUE)
plot(svmtst.auc, col='red', add=TRUE)
legend("bottomright", legend=c("Training", "Test"),
        col=c("green", "red"), lwd=2, cex=0.8, bty='n')
abline(a = 0, b = 1)

#model 2
system.time( svmNRC2 <- svm(as.factor(hiLo) ~., data = revDTM_sentiNrc_trn
%>% select(-review_id), kernel="radial", cost=10, gamma=0.5, scale=FALSE, decision.values = TRUE)) 

revDTM_predTrn_svmNRC2<-predict(svmNRC2, revDTM_sentiNrc_trn, decision.values = TRUE)
table(actual= revDTM_sentiNrc_trn$hiLo, predicted= revDTM_predTrn_svmNRC2)
revDTM_predTst_svmNRC2<-predict(svmNRC2, revDTM_sentiNrc_tst, decision.values = TRUE)
table(actual= revDTM_sentiNrc_tst$hiLo, predicted= revDTM_predTst_svmNRC2)

svmtrn.roc <- prediction(attributes(revDTM_predTrn_svmNRC2)$decision.values, revDTM_sentiNrc_trn$hiLo)
svm2trn.auc <- performance(svmtrn.roc, 'tpr', 'fpr')
aucsvmtrn <- performance(svmtrn.roc, 'auc')

svmtst.roc <- prediction(attributes(revDTM_predTst_svmNRC2)$decision.values, revDTM_sentiNrc_tst$hiLo)
svm2tst.auc <- performance(svmtst.roc, 'tpr', 'fpr')
aucsvmtst <- performance(svmtst.roc, 'auc')

auc(as.numeric(revDTM_sentiNrc_trn$hiLo), as.numeric(revDTM_predTrn_svmNRC2))

auc(as.numeric(revDTM_sentiNrc_tst$hiLo), as.numeric(revDTM_predTst_svmNRC2))

#ROC plot
plot(svm2trn.auc)
plot(svm2trn.auc, col='green', add = TRUE, legacy.axes = TRUE)
plot(svm2tst.auc, col='red', add=TRUE)
legend("bottomright", legend=c("Training", "Test"),
        col=c("green", "red"), lwd=2, cex=0.8, bty='n')
abline(a = 0, b = 1)

#Model 3

system.time( svmNRC3 <- svm(as.factor(hiLo) ~., data = revDTM_sentiNrc_trn
%>% select(-review_id), kernel="radial", cost=10, gamma=1, scale=FALSE, decision.values = TRUE)) 

revDTM_predTrn_svmNRC3<-predict(svmNRC3, revDTM_sentiNrc_trn, decision.values = TRUE)
table(actual= revDTM_sentiNrc_trn$hiLo, predicted= revDTM_predTrn_svmNRC3)
revDTM_predTst_svmNRC3<-predict(svmNRC3, revDTM_sentiNrc_tst, decision.values = TRUE)
table(actual= revDTM_sentiNrc_tst$hiLo, predicted= revDTM_predTst_svmNRC3)

svmtrn.roc <- prediction(attributes(revDTM_predTrn_svmNRC3)$decision.values, revDTM_sentiNrc_trn$hiLo)
svm3trn.auc <- performance(svmtrn.roc, 'tpr', 'fpr')
aucsvmtrn <- performance(svmtrn.roc, 'auc')
aucsvmtrn

svmtst.roc <- prediction(attributes(revDTM_predTst_svmNRC3)$decision.values, revDTM_sentiNrc_tst$hiLo)
svm3tst.auc <- performance(svmtst.roc, 'tpr', 'fpr')
aucsvmtst <- performance(svmtst.roc, 'auc')
aucsvmtst

auc(as.numeric(revDTM_sentiNrc_trn$hiLo), as.numeric(revDTM_predTrn_svmNRC3))

auc(as.numeric(revDTM_sentiNrc_tst$hiLo), as.numeric(revDTM_predTst_svmNRC3))

#ROC plot
plot(svm3trn.auc)
plot(svm3trn.auc, col='green', add = TRUE, legacy.axes = TRUE)
plot(svm3tst.auc, col='red', add=TRUE)
legend("bottomright", legend=c("Training", "Test"),
        col=c("green", "red"), lwd=2, cex=0.8, bty='n')
abline(a = 0, b = 1)

#Model 4

system.time( svmNRC4 <- svm(as.factor(hiLo) ~., data = revDTM_sentiNrc_trn
%>% select(-review_id), kernel="radial", cost=1, gamma=2, scale=FALSE, decision.values = TRUE)) 

revDTM_predTrn_svmNRC4<-predict(svmNRC4, revDTM_sentiNrc_trn, decision.values = TRUE)
table(actual= revDTM_sentiNrc_trn$hiLo, predicted= revDTM_predTrn_svmNRC4)
revDTM_predTst_svmNRC4<-predict(svmNRC4, revDTM_sentiNrc_tst, decision.values = TRUE)
table(actual= revDTM_sentiNrc_tst$hiLo, predicted= revDTM_predTst_svmNRC4)

svmtrn.roc <- prediction(attributes(revDTM_predTrn_svmNRC4)$decision.values, revDTM_sentiNrc_trn$hiLo)
svm4trn.auc <- performance(svmtrn.roc, 'tpr', 'fpr')
aucsvmtrn <- performance(svmtrn.roc, 'auc')
aucsvmtrn

svmtst.roc <- prediction(attributes(revDTM_predTst_svmNRC4)$decision.values, revDTM_sentiNrc_tst$hiLo)
svm4tst.auc <- performance(svmtst.roc, 'tpr', 'fpr')
aucsvmtst <- performance(svmtst.roc, 'auc')
aucsvmtst

auc(as.numeric(revDTM_sentiNrc_trn$hiLo), as.numeric(revDTM_predTrn_svmNRC4))

auc(as.numeric(revDTM_sentiNrc_tst$hiLo), as.numeric(revDTM_predTst_svmNRC4))

#ROC plot
plot(svm4trn.auc)
plot(svm4trn.auc, col='green', add = TRUE, legacy.axes = TRUE)
plot(svm4tst.auc, col='red', add=TRUE)
legend("bottomright", legend=c("Training", "Test"),
        col=c("green", "red"), lwd=2, cex=0.8, bty='n')
abline(a = 0, b = 1)
```

#Naive Bayes for NRC
```{r message=FALSE, cache=TRUE}

library(e1071)

#model 2 - without laplace
nbModel2<-naiveBayes(hiLo ~ ., data=revDTM_sentiNrc_trn %>% select(-review_id))

#training data
revSentinrc_NBpredTrn<-predict(nbModel2, revDTM_sentiNrc_trn, type = "raw")
cmtrn2 <- table(actual=revDTM_sentiNrc_trn$hiLo, preds=revSentinrc_NBpredTrn[,2]>0.5)
# 43%

#test data
revSentinrc_NBpredTst<-predict(nbModel2, revDTM_sentiNrc_tst, type = "raw")
cmtst2 <- table(actual=revDTM_sentiNrc_tst$hiLo, preds=revSentinrc_NBpredTst[,2]>0.5)
#44.04%

#AUC values
auc(as.numeric(revDTM_sentiNrc_trn$hiLo), revSentinrc_NBpredTrn[,2]) # 66.04%
auc(as.numeric(revDTM_sentiNrc_tst$hiLo), revSentinrc_NBpredTst[,2]) # 68.47%


#model 2b - with laplace
nbModel2<-naiveBayes(hiLo ~ ., data=revDTM_sentiNrc_trn %>% select(-review_id), laplace = 2)

#training data
revSentinrc_NBpredTrn<-predict(nbModel2, revDTM_sentiNrc_trn, type = "raw")
cmtrn2 <- table(actual=revDTM_sentiNrc_trn$hiLo, preds=revSentinrc_NBpredTrn[,2]>0.5)

#test data
revSentinrc_NBpredTst<-predict(nbModel2, revDTM_sentiNrc_tst, type = "raw")
cmtst2 <- table(actual=revDTM_sentiNrc_tst$hiLo, preds=revSentinrc_NBpredTst[,2]>0.5)

#AUC values
auc(as.numeric(revDTM_sentiNrc_trn$hiLo), revSentinrc_NBpredTrn[,2])
auc(as.numeric(revDTM_sentiNrc_tst$hiLo), revSentinrc_NBpredTst[,2])


```


# ###################    Afinn      ####################

```{r}
#create Document Term Matrix
revDTM_sentiAfinn <- rrSenti_afinn %>%  pivot_wider(id_cols = c(review_id,stars), names_from = word, values_from = tf_idf)  %>% ungroup()

#Dimensions for revDTM_sentiAfinn
revDTM_sentiAfinn %>% dim()

#filter out the reviews with stars=3
#calculate hiLo sentiment(1 is assigned to 4 and 5/-1 is assigned to 1 and 2)
revDTM_sentiAfinn <- revDTM_sentiAfinn %>% filter(stars!=3) %>% mutate(hiLo=ifelse(stars<=2, -1, 1)) %>% select(-stars)

#Dimensions for revDTM_sentiAfinn
revDTM_sentiAfinn %>% dim()

#replace all NAs with zero
revDTM_sentiAfinn<-revDTM_sentiAfinn %>% replace(., is.na(.), 0)

#convert hiLo from num to factor
revDTM_sentiAfinn$hiLo<- as.factor(revDTM_sentiAfinn$hiLo)

#no of reviews with 1, -1 class
Afinn_hiLo_count <- revDTM_sentiAfinn %>% group_by(hiLo) %>% tally()
write.csv(Afinn_hiLo_count, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/Afinn_hiLo_count.csv")

set.seed(1234)

#split the data into training and test dataset (50:50)
revDTM_sentiAfinn_split<- initial_split(revDTM_sentiAfinn, 0.5)
revDTM_sentiAfinn_trn  <- training(revDTM_sentiAfinn_split)
revDTM_sentiAfinn_tst  <- testing(revDTM_sentiAfinn_split)
```

#RF Model
```{r}
rfModel1<-ranger(dependent.variable.name = "hiLo", data=revDTM_sentiAfinn_trn %>% select(-review_id), num.trees = 500, importance='permutation', probability = TRUE)

#Make predictions from the model on trn and test dataset
revSentiAfinn_predTrn<- predict(rfModel1, revDTM_sentiAfinn_trn %>% select(-review_id))
revSentiAfinn_predTst<- predict(rfModel1, revDTM_sentiAfinn_tst %>% select(-review_id))

#find the optimal TH
rocTrn <- roc(revDTM_sentiAfinn_trn$hiLo, revSentiAfinn_predTrn$predictions[,2], levels=c(-1, 1))
rocTst <- roc(revDTM_sentiAfinn_tst$hiLo, revSentiAfinn_predTst$predictions[,2], levels=c(-1, 1))

plot.roc(rocTrn, col='blue', legacy.axes = TRUE)
plot.roc(rocTst, col='red', add=TRUE)
legend("bottomright", legend=c("Training", "Test"),
        col=c("blue", "red"), lwd=2, cex=0.8, bty='n')

#best threshold from ROC
bThr<-coords(rocTrn, "best", ret="threshold", transpose = FALSE)
bThr <- as.numeric(bThr)

#Confusion Matrix at bThr for Trn and Tst dataset
a <- table(actual=revDTM_sentiAfinn_trn$hiLo, preds=revSentiAfinn_predTrn$predictions[,2]>bThr)
b <- table(actual=revDTM_sentiAfinn_tst$hiLo, preds=revSentiAfinn_predTst$predictions[,2]>bThr)

write.csv(a, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/bthr_trn.csv")
write.csv(b, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/bthr_tst.csv")

#Confusion Matrix at 0.5 for Trn and Tst dataset
c <- table(actual=revDTM_sentiAfinn_trn$hiLo, preds=revSentiAfinn_predTrn$predictions[,2]>0.5)
d <- table(actual=revDTM_sentiAfinn_tst$hiLo, preds=revSentiAfinn_predTst$predictions[,2]>0.5)

write.csv(c, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/0.5_trn.csv")
write.csv(d, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/0.5_tst.csv")
```

#SVM Model
```{r}
#model 1
system.time( svmAfinn1 <- svm(as.factor(hiLo) ~., data = revDTM_sentiAfinn_trn
%>% select(-review_id), kernel="radial", cost=50, gamma=1, scale=FALSE, decision.values = TRUE)) 

revDTM_predTrn_svmAfinn1<-predict(svmAfinn1, revDTM_sentiAfinn_trn, decision.values = TRUE)
table(actual= revDTM_sentiAfinn_trn$hiLo, predicted= revDTM_predTrn_svmAfinn1)
revDTM_predTst_svmAfinn1<-predict(svmAfinn1, revDTM_sentiAfinn_tst, decision.values = TRUE)
table(actual= revDTM_sentiAfinn_tst$hiLo, predicted= revDTM_predTst_svmAfinn1)

svmtrn.roc <- prediction(attributes(revDTM_predTrn_svmAfinn1)$decision.values, revDTM_sentiAfinn_trn$hiLo)
svmtrn.auc <- performance(svm.roc, 'tpr', 'fpr')
aucsvmtrn <- performance(svm.roc, 'auc')

svmtst.roc <- prediction(attributes(revDTM_predTst_svmAfinn1)$decision.values, revDTM_sentiAfinn_tst$hiLo)
svmtst.auc <- performance(svm.roc, 'tpr', 'fpr')
aucsvmtst <- performance(svm.roc, 'auc')

plot(svmtrn.auc, col='green', add = TRUE, legacy.axes = TRUE)
plot(svmtst.auc, col='red', add=TRUE)
legend("bottomright", legend=c("Training", "Test"),
        col=c("green", "red"), lwd=2, cex=0.8, bty='n')
abline(a = 0, b = 1)

#model 2
system.time( svmAfinn2 <- svm(as.factor(hiLo) ~., data = revDTM_sentiAfinn_trn
%>% select(-review_id), kernel="radial", cost=10, gamma=0.5, scale=FALSE, decision.values = TRUE)) 

revDTM_predTrn_svmAfinn2<-predict(svmAfinn2, revDTM_sentiAfinn_trn, decision.values = TRUE)
table(actual= revDTM_sentiAfinn_trn$hiLo, predicted= revDTM_predTrn_svmAfinn2)
revDTM_predTst_svmAfinn2<-predict(svmAfinn2, revDTM_sentiAfinn_tst, decision.values = TRUE)
table(actual= revDTM_sentiAfinn_tst$hiLo, predicted= revDTM_predTst_svmAfinn2)

svmtrn.roc <- prediction(attributes(revDTM_predTrn_svmAfinn2)$decision.values, revDTM_sentiAfinn_trn$hiLo)
svm2trn.auc <- performance(svmtrn.roc, 'tpr', 'fpr')
aucsvmtrn <- performance(svmtrn.roc, 'auc')

svmtst.roc <- prediction(attributes(revDTM_predTst_svmAfinn2)$decision.values, revDTM_sentiAfinn_tst$hiLo)
svm2tst.auc <- performance(svmtst.roc, 'tpr', 'fpr')
aucsvmtst <- performance(svmtst.roc, 'auc')

auc(as.numeric(revDTM_sentiAfinn_trn$hiLo), as.numeric(revDTM_predTrn_svmAfinn2))

auc(as.numeric(revDTM_sentiAfinn_tst$hiLo), as.numeric(revDTM_predTst_svmAfinn2))

#ROC plot
plot(svm2trn.auc)
plot(svm2trn.auc, col='green', add = TRUE, legacy.axes = TRUE)
plot(svm2tst.auc, col='red', add=TRUE)
legend("bottomright", legend=c("Training", "Test"),
        col=c("green", "red"), lwd=2, cex=0.8, bty='n')
abline(a = 0, b = 1)

#Model 3

system.time( svmAfinn3 <- svm(as.factor(hiLo) ~., data = revDTM_sentiAfinn_trn
%>% select(-review_id), kernel="radial", cost=10, gamma=1, scale=FALSE, decision.values = TRUE)) 

revDTM_predTrn_svmAfinn3<-predict(svmAfinn3, revDTM_sentiAfinn_trn, decision.values = TRUE)
table(actual= revDTM_sentiAfinn_trn$hiLo, predicted= revDTM_predTrn_svmAfinn3)
revDTM_predTst_svmAfinn3<-predict(svmAfinn3, revDTM_sentiAfinn_tst, decision.values = TRUE)
table(actual= revDTM_sentiAfinn_tst$hiLo, predicted= revDTM_predTst_svmAfinn3)

svmtrn.roc <- prediction(attributes(revDTM_predTrn_svmAfinn3)$decision.values, revDTM_sentiAfinn_trn$hiLo)
svm3trn.auc <- performance(svmtrn.roc, 'tpr', 'fpr')
aucsvmtrn <- performance(svmtrn.roc, 'auc')
aucsvmtrn

svmtst.roc <- prediction(attributes(revDTM_predTst_svmAfinn3)$decision.values, revDTM_sentiAfinn_tst$hiLo)
svm3tst.auc <- performance(svmtst.roc, 'tpr', 'fpr')
aucsvmtst <- performance(svmtst.roc, 'auc')
aucsvmtst

auc(as.numeric(revDTM_sentiAfinn_trn$hiLo), as.numeric(revDTM_predTrn_svmAfinn3))

auc(as.numeric(revDTM_sentiAfinn_tst$hiLo), as.numeric(revDTM_predTst_svmAfinn3))

#ROC plot
plot(svm3trn.auc)
plot(svm3trn.auc, col='green', add = TRUE, legacy.axes = TRUE)
plot(svm3tst.auc, col='red', add=TRUE)
legend("bottomright", legend=c("Training", "Test"),
        col=c("green", "red"), lwd=2, cex=0.8, bty='n')
abline(a = 0, b = 1)

#Model 4

system.time( svmAfinn4 <- svm(as.factor(hiLo) ~., data = revDTM_sentiAfinn_trn
%>% select(-review_id), kernel="radial", cost=1, gamma=2, scale=FALSE, decision.values = TRUE)) 

revDTM_predTrn_svmAfinn4<-predict(svmAfinn4, revDTM_sentiAfinn_trn, decision.values = TRUE)
table(actual= revDTM_sentiAfinn_trn$hiLo, predicted= revDTM_predTrn_svmAfinn4)
revDTM_predTst_svmAfinn4<-predict(svmAfinn4, revDTM_sentiAfinn_tst, decision.values = TRUE)
table(actual= revDTM_sentiAfinn_tst$hiLo, predicted= revDTM_predTst_svmAfinn4)

svmtrn.roc <- prediction(attributes(revDTM_predTrn_svmAfinn4)$decision.values, revDTM_sentiAfinn_trn$hiLo)
svm4trn.auc <- performance(svmtrn.roc, 'tpr', 'fpr')
aucsvmtrn <- performance(svmtrn.roc, 'auc')
aucsvmtrn

svmtst.roc <- prediction(attributes(revDTM_predTst_svmAfinn4)$decision.values, revDTM_sentiAfinn_tst$hiLo)
svm4tst.auc <- performance(svmtst.roc, 'tpr', 'fpr')
aucsvmtst <- performance(svmtst.roc, 'auc')
aucsvmtst

auc(as.numeric(revDTM_sentiAfinn_trn$hiLo), as.numeric(revDTM_predTrn_svmAfinn4))

auc(as.numeric(revDTM_sentiAfinn_tst$hiLo), as.numeric(revDTM_predTst_svmAfinn4))

#ROC plot
plot(svm4trn.auc)
plot(svm4trn.auc, col='green', add = TRUE, legacy.axes = TRUE)
plot(svm4tst.auc, col='red', add=TRUE)
legend("bottomright", legend=c("Training", "Test"),
        col=c("green", "red"), lwd=2, cex=0.8, bty='n')
abline(a = 0, b = 1)

```

#Naive Bayes
```{r message=FALSE, cache=TRUE}

library(e1071)

#model 3 - without laplace
nbModel3 <-naiveBayes(hiLo ~ ., data=revDTM_sentiAfinn_trn %>% select(-review_id))

#training data
revSentiafinn_NBpredTrn<-predict(nbModel3, revDTM_sentiAfinn_trn, type = "raw")
cmtrn3 <- table(actual=revDTM_sentiAfinn_trn$hiLo, preds=revSentiafinn_NBpredTrn[,2]>0.5)
#68.16

#test data
revSentiafinn_NBpredTst<-predict(nbModel3, revDTM_sentiAfinn_tst, type = "raw")
cmtst3 <- table(actual=revDTM_sentiAfinn_tst$hiLo, preds=revSentiafinn_NBpredTst[,2]>0.5)
#68.61

auc(as.numeric(revDTM_sentiAfinn_trn$hiLo), revSentiafinn_NBpredTrn[,2]) #72.72
auc(as.numeric(revDTM_sentiAfinn_tst$hiLo), revSentiafinn_NBpredTst[,2])  #73.16


#model 3b - with laplace
nbModel3 <-naiveBayes(hiLo ~ ., data=revDTM_sentiAfinn_trn %>% select(-review_id), laplace =2)

#training data
revSentiafinn_NBpredTrn<-predict(nbModel3, revDTM_sentiAfinn_trn, type = "raw")
cmtrn3 <- table(actual=revDTM_sentiAfinn_trn$hiLo, preds=revSentiafinn_NBpredTrn[,2]>0.5)

#test data
revSentiafinn_NBpredTst<-predict(nbModel3, revDTM_sentiAfinn_tst, type = "raw")
cmtst3 <- table(actual=revDTM_sentiAfinn_tst$hiLo, preds=revSentiafinn_NBpredTst[,2]>0.5)


auc(as.numeric(revDTM_sentiAfinn_trn$hiLo), revSentiafinn_NBpredTrn[,2])
auc(as.numeric(revDTM_sentiAfinn_tst$hiLo), revSentiafinn_NBpredTst[,2])

```


# ### Combination of Dictionaries ### #
```{r}
#change the column 'value' to 'sentiment' in Afinn to combine the matched words of three dictionaries
names(rrSenti_afinn)[names(rrSenti_afinn) == "value"] <- "sentiment"

#Dimensions for individual matched words from dictionaries
rrSenti_bing %>% dim()
rrSenti_nrc1 %>% dim()
rrSenti_afinn %>% dim()

#combine matched words from the three dictionaries
rrSenti_combo <- rbind(rrSenti_bing, rrSenti_nrc1, rrSenti_afinn)

#Dimensions for combined set of matched words from dictionaries
rrSenti_combo %>% dim()

#Dimensions for the distinct word tokens in rrSenti_combo
rrSenti_combo %>% distinct(word) %>% dim()

#make a copy of rrSenti_combo
rrSenti_combo1 <- rrSenti_combo

#remove duplicates from rrSenti_combo
rrSenti_combo <-rrSenti_combo[,-8]
rrSenti_combo <-rrSenti_combo[!duplicated(rrSenti_combo), ]

#Dimensions for rrSenti_combo 
rrSenti_combo %>% dim()

#Dimensions for the distinct word tokens in rrSenti_combo
rrSenti_combo %>% distinct(word) %>% dim()

#create Document Term Matrix
revDTM_sentiCombo <- rrSenti_combo %>%  pivot_wider(id_cols = c(review_id,stars), names_from = word, values_from = tf_idf)  %>% ungroup()

#Dimensions for revDTM_sentiCombo
revDTM_sentiCombo %>% dim()

#filter out the reviews with stars=3
#calculate hiLo sentiment(1 is assigned to 4 and 5/-1 is assigned to 1 and 2)
revDTM_sentiCombo <- revDTM_sentiCombo %>% filter(stars!=3) %>% mutate(hiLo=ifelse(stars<=2, -1, 1)) %>% select(-stars)

#Dimensions for revDTM_sentiCombo
revDTM_sentiCombo %>% dim()

#replace all NAs with zero
revDTM_sentiCombo<-revDTM_sentiCombo %>% replace(., is.na(.), 0)

#convert hiLo from num to factor
revDTM_sentiCombo$hiLo<- as.factor(revDTM_sentiCombo$hiLo)

#no of reviews with 1, -1 class
Combo_hiLo_count <- revDTM_sentiCombo %>% group_by(hiLo) %>% tally()
write.csv(Combo_hiLo_count, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/Combo_hiLo_count.csv")

set.seed(1234)

#split the data into training and test dataset (50:50)
revDTM_sentiCombo_split<- initial_split(revDTM_sentiCombo, 0.5)
revDTM_sentiCombo_trn  <- training(revDTM_sentiCombo_split)
revDTM_sentiCombo_tst  <- testing(revDTM_sentiCombo_split)
```

#SVM Model
```{r}
#model 1
system.time( svmCombo1 <- svm(as.factor(hiLo) ~., data = revDTM_sentiCombo_trn
%>% select(-review_id), kernel="radial", cost=50, gamma=1, scale=FALSE, decision.values = TRUE)) 

revDTM_predTrn_svmCombo1<-predict(svmCombo1, revDTM_sentiCombo_trn, decision.values = TRUE)
table(actual= revDTM_sentiCombo_trn$hiLo, predicted= revDTM_predTrn_svmCombo1)
revDTM_predTst_svmCombo1<-predict(svmCombo1, revDTM_sentiCombo_tst, decision.values = TRUE)
table(actual= revDTM_sentiCombo_tst$hiLo, predicted= revDTM_predTst_svmCombo1)

svmtrn.roc <- prediction(attributes(revDTM_predTrn_svmCombo1)$decision.values, revDTM_sentiCombo_trn$hiLo)
svmtrn.auc <- performance(svmtrn.roc, 'tpr', 'fpr')
aucsvmtrn <- performance(svmtrn.roc, 'auc')

svmtst.roc <- prediction(attributes(revDTM_predTst_svmCombo1)$decision.values, revDTM_sentiCombo_tst$hiLo)
svmtst.auc <- performance(svmtst.roc, 'tpr', 'fpr')
aucsvmtst <- performance(svmtst.roc, 'auc')

plot(svmtrn.auc, col='green', add = TRUE, legacy.axes = TRUE)
plot(svmtst.auc, col='red', add=TRUE)
legend("bottomright", legend=c("Training", "Test"),
        col=c("green", "red"), lwd=2, cex=0.8, bty='n')
abline(a = 0, b = 1)

#model 2
system.time( svmCombo2 <- svm(as.factor(hiLo) ~., data = revDTM_sentiCombo_trn
%>% select(-review_id), kernel="radial", cost=10, gamma=0.5, scale=FALSE, decision.values = TRUE)) 

revDTM_predTrn_svmCombo2<-predict(svmCombo2, revDTM_sentiCombo_trn, decision.values = TRUE)
table(actual= revDTM_sentiCombo_trn$hiLo, predicted= revDTM_predTrn_svmCombo2)
revDTM_predTst_svmCombo2<-predict(svmCombo2, revDTM_sentiCombo_tst, decision.values = TRUE)
table(actual= revDTM_sentiCombo_tst$hiLo, predicted= revDTM_predTst_svmCombo2)

svmtrn.roc <- prediction(attributes(revDTM_predTrn_svmCombo2)$decision.values, revDTM_sentiCombo_trn$hiLo)
svm2trn.auc <- performance(svmtrn.roc, 'tpr', 'fpr')
aucsvmtrn <- performance(svmtrn.roc, 'auc')

svmtst.roc <- prediction(attributes(revDTM_predTst_svmCombo2)$decision.values, revDTM_sentiCombo_tst$hiLo)
svm2tst.auc <- performance(svmtst.roc, 'tpr', 'fpr')
aucsvmtst <- performance(svmtst.roc, 'auc')

auc(as.numeric(revDTM_sentiCombo_trn$hiLo), as.numeric(revDTM_predTrn_svmCombo2))

auc(as.numeric(revDTM_sentiCombo_tst$hiLo), as.numeric(revDTM_predTst_svmCombo2))

#ROC plot
plot(svm2trn.auc)
plot(svm2trn.auc, col='green', add = TRUE, legacy.axes = TRUE)
plot(svm2tst.auc, col='red', add=TRUE)
legend("bottomright", legend=c("Training", "Test"),
        col=c("green", "red"), lwd=2, cex=0.8, bty='n')
abline(a = 0, b = 1)

#Model 3

system.time( svmCombo3 <- svm(as.factor(hiLo) ~., data = revDTM_sentiCombo_trn
%>% select(-review_id), kernel="radial", cost=10, gamma=1, scale=FALSE, decision.values = TRUE)) 

revDTM_predTrn_svmCombo3<-predict(svmCombo3, revDTM_sentiCombo_trn, decision.values = TRUE)
table(actual= revDTM_sentiCombo_trn$hiLo, predicted= revDTM_predTrn_svmCombo3)
revDTM_predTst_svmCombo3<-predict(svmCombo3, revDTM_sentiCombo_tst, decision.values = TRUE)
table(actual= revDTM_sentiCombo_tst$hiLo, predicted= revDTM_predTst_svmCombo3)

svmtrn.roc <- prediction(attributes(revDTM_predTrn_svmCombo3)$decision.values, revDTM_sentiCombo_trn$hiLo)
svm3trn.auc <- performance(svmtrn.roc, 'tpr', 'fpr')
aucsvmtrn <- performance(svmtrn.roc, 'auc')
aucsvmtrn

svmtst.roc <- prediction(attributes(revDTM_predTst_svmCombo3)$decision.values, revDTM_sentiCombo_tst$hiLo)
svm3tst.auc <- performance(svmtst.roc, 'tpr', 'fpr')
aucsvmtst <- performance(svmtst.roc, 'auc')
aucsvmtst

auc(as.numeric(revDTM_sentiCombo_trn$hiLo), as.numeric(revDTM_predTrn_svmCombo3))

auc(as.numeric(revDTM_sentiCombo_tst$hiLo), as.numeric(revDTM_predTst_svmCombo3))

#ROC plot
plot(svm3trn.auc)
plot(svm3trn.auc, col='green', add = TRUE, legacy.axes = TRUE)
plot(svm3tst.auc, col='red', add=TRUE)
legend("bottomright", legend=c("Training", "Test"),
        col=c("green", "red"), lwd=2, cex=0.8, bty='n')
abline(a = 0, b = 1)

#Model 4

system.time( svmCombo4 <- svm(as.factor(hiLo) ~., data = revDTM_sentiCombo_trn
%>% select(-review_id), kernel="radial", cost=1, gamma=2, scale=FALSE, decision.values = TRUE)) 

revDTM_predTrn_svmCombo4<-predict(svmCombo4, revDTM_sentiCombo_trn, decision.values = TRUE)
table(actual= revDTM_sentiCombo_trn$hiLo, predicted= revDTM_predTrn_svmCombo4)
revDTM_predTst_svmCombo4<-predict(svmCombo4, revDTM_sentiCombo_tst, decision.values = TRUE)
table(actual= revDTM_sentiCombo_tst$hiLo, predicted= revDTM_predTst_svmCombo4)

svmtrn.roc <- prediction(attributes(revDTM_predTrn_svmCombo4)$decision.values, revDTM_sentiCombo_trn$hiLo)
svm4trn.auc <- performance(svmtrn.roc, 'tpr', 'fpr')
aucsvmtrn <- performance(svmtrn.roc, 'auc')
aucsvmtrn

svmtst.roc <- prediction(attributes(revDTM_predTst_svmCombo4)$decision.values, revDTM_sentiCombo_tst$hiLo)
svm4tst.auc <- performance(svmtst.roc, 'tpr', 'fpr')
aucsvmtst <- performance(svmtst.roc, 'auc')
aucsvmtst

auc(as.numeric(revDTM_sentiCombo_trn$hiLo), as.numeric(revDTM_predTrn_svmCombo4))

auc(as.numeric(revDTM_sentiCombo_tst$hiLo), as.numeric(revDTM_predTst_svmCombo4))

#ROC plot
plot(svm4trn.auc)
plot(svm4trn.auc, col='green', add = TRUE, legacy.axes = TRUE)
plot(svm4tst.auc, col='red', add=TRUE)
legend("bottomright", legend=c("Training", "Test"),
        col=c("green", "red"), lwd=2, cex=0.8, bty='n')
abline(a = 0, b = 1)

```

#RF Model
```{r}
rfModel1<-ranger(dependent.variable.name = "hiLo", data=revDTM_sentiCombo_trn %>% select(-review_id), num.trees = 500, importance='permutation', probability = TRUE)

#Make predictions from the model on trn and test dataset
revSentiCombo_predTrn<- predict(rfModel1, revDTM_sentiCombo_trn %>% select(-review_id))
revSentiCombo_predTst<- predict(rfModel1, revDTM_sentiCombo_tst %>% select(-review_id))

#find the optimal TH
rocTrn <- roc(revDTM_sentiCombo_trn$hiLo, revSentiCombo_predTrn$predictions[,2], levels=c(-1, 1))
rocTst <- roc(revDTM_sentiCombo_tst$hiLo, revSentiCombo_predTst$predictions[,2], levels=c(-1, 1))

plot.roc(rocTrn, col='blue', legacy.axes = TRUE)
plot.roc(rocTst, col='red', add=TRUE)
legend("bottomright", legend=c("Training", "Test"),
        col=c("blue", "red"), lwd=2, cex=0.8, bty='n')

#best threshold from ROC
bThr<-coords(rocTrn, "best", ret="threshold", transpose = FALSE)
bThr <- as.numeric(bThr)

#Confusion Matrix at bThr for Trn and Tst dataset
a <- table(actual=revDTM_sentiCombo_trn$hiLo, preds=revSentiCombo_predTrn$predictions[,2]>bThr)
b <- table(actual=revDTM_sentiCombo_tst$hiLo, preds=revSentiCombo_predTst$predictions[,2]>bThr)

write.csv(a, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/bthr_trn.csv")
write.csv(b, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/bthr_tst.csv")

#Confusion Matrix at 0.5 for Trn and Tst dataset
c <- table(actual=revDTM_sentiCombo_trn$hiLo, preds=revSentiCombo_predTrn$predictions[,2]>0.5)
d <- table(actual=revDTM_sentiCombo_tst$hiLo, preds=revSentiCombo_predTst$predictions[,2]>0.5)

write.csv(c, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/0.5_trn.csv")
write.csv(d, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/0.5_tst.csv")
```

#Naive Bayes
```{r message=FALSE, cache=TRUE}

library(e1071)

#model 4 - without laplace
nbModel4 <-naiveBayes(hiLo ~ ., data=revDTM_sentiCombo_trn %>% select(-review_id))

#training data
revSentiCombo_NBpredTrn<-predict(nbModel4, revDTM_sentiCombo_trn, type = "raw")
cmtrn4 <- table(actual=revDTM_sentiCombo_trn$hiLo, preds=revSentiCombo_NBpredTrn[,2]>0.5)
#48.34%

#test data
revSentiCombo_NBpredTst<-predict(nbModel4, revDTM_sentiCombo_tst, type = "raw")
cmtst4 <- table(actual=revDTM_sentiCombo_tst$hiLo, preds=revSentiCombo_NBpredTst[,2]>0.5)
#49.41%

auc(as.numeric(revDTM_sentiCombo_trn$hiLo), revSentiCombo_NBpredTrn[,2]) # 66.92%
auc(as.numeric(revDTM_sentiCombo_tst$hiLo), revSentiCombo_NBpredTst[,2])  # 70.08%


#model 4b - with laplace

nbModel4 <-naiveBayes(hiLo ~ ., data=revDTM_sentiCombo_trn %>% select(-review_id), laplace = 2)

#training data
revSentiCombo_NBpredTrn<-predict(nbModel4, revDTM_sentiCombo_trn, type = "raw")
cmtrn4 <- table(actual=revDTM_sentiCombo_trn$hiLo, preds=revSentiCombo_NBpredTrn[,2]>0.5)


#test data
revSentiCombo_NBpredTst<-predict(nbModel4, revDTM_sentiCombo_tst, type = "raw")
cmtst4 <- table(actual=revDTM_sentiCombo_tst$hiLo, preds=revSentiCombo_NBpredTst[,2]>0.5)


auc(as.numeric(revDTM_sentiCombo_trn$hiLo), revSentiCombo_NBpredTrn[,2]) 
auc(as.numeric(revDTM_sentiCombo_tst$hiLo), revSentiCombo_NBpredTst[,2])



```

#Q4(b)

# #######################################################
# Subpart (ii) - Models on broader set of terms
# #######################################################

# ################### Pre Processsing ####################

```{r}
#Number of reviews each word occurs in
rWords<-rrTokens %>% group_by(word) %>% summarise(nr=n()) %>% arrange(desc(nr))

#ungroup rWords
rWords <- ungroup(rWords)

#dimension of rWords
rWords %>% dim()

#Dimensions for the distinct word tokens in rWords
rWords %>% distinct(word) %>% dim()

#Words that occur in max reviews
a <- top_n(rWords, 20) %>% mutate(word=reorder(word,nr))
write.csv(a, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/a.csv")
ggplot(a, aes(word, nr, fill=word)) +geom_col(color="#FFFFFF")+coord_flip() + scale_y_continuous(name = "Number of Reviews") + scale_x_discrete(name = "Words") + theme(axis.text.y = element_text(hjust = 1, face = "bold", size = 8))

#Words that occur in min reviews
b <- top_n(rWords, -20) %>% mutate(word=reorder(word,nr))
write.csv(b, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/b.csv")
ggplot(b, aes(word, nr, fill=word)) +geom_col(color="#FFFFFF")+coord_flip() + scale_y_continuous(name = "Number of Reviews") + scale_x_discrete(name = "Words") + theme(axis.text.y = element_text(hjust = 1, face = "bold", size = 8))

#we want to remove words which occur in > 4500 reviews and less than 30 reviews
reduced_rWords<-rWords %>% filter(nr< 4500 & nr > 30)

#dimension of reduced_rWords
reduced_rWords %>% dim()

#Dimensions for the distinct word tokens in reduced_rWords
reduced_rWords %>% distinct(word) %>% dim()

#reduce the rrTokens data to keep only the reduced set of words
reduced_rrTokens <- left_join(reduced_rWords, rrTokens)

#dimension of reduced_rrTokens
reduced_rrTokens %>% dim()

#Dimensions for the distinct word tokens in reduced_rrTokens
reduced_rrTokens %>% distinct(word) %>% dim()

#create Document Term Matrix
revDTM  <- reduced_rrTokens %>%  pivot_wider(id_cols = c(review_id,stars), names_from = word, values_from = tf_idf)  %>% ungroup()

#dimensions of DTM
dim(revDTM)

#filter out the reviews with stars=3
#calculate hiLo sentiment(1 is assigned to 4 and 5/-1 is assigned to 1 and 2)
revDTM <- revDTM %>% filter(stars!=3) %>% mutate(hiLo=ifelse(stars<=2, -1, 1)) %>% select(-stars)

#replace all NAs with zero
revDTM<-revDTM %>% replace(., is.na(.), 0)

#convert hiLo from num to factor
revDTM$hiLo<-as.factor(revDTM$hiLo)

#no of reviews with 1, -1 class
revDTM_hiLo_count <- revDTM %>% group_by(hiLo) %>% tally()
write.csv(revDTM_hiLo_count, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/revDTM_hiLo_count.csv")

set.seed(1234)

#split the data into training and test dataset (50:50)
revDTM_split<- initial_split(revDTM, 0.5)
revDTM_trn<- training(revDTM_split)
revDTM_tst<- testing(revDTM_split)
```

#Random Forest
```{r}
rfModel1<-ranger(dependent.variable.name = "hiLo", data=revDTM_trn %>% select(-review_id), num.trees = 500, importance='permutation', probability = TRUE)

#Make predictions from the model on trn and test dataset
rev_predTrn<- predict(rfModel1, revDTM_trn %>% select(-review_id))
rev_predTst<- predict(rfModel1, revDTM_tst %>% select(-review_id))

#find the optimal TH
rocTrn <- roc(revDTM_trn$hiLo, rev_predTrn$predictions[,2], levels=c(-1, 1))
rocTst <- roc(revDTM_tst$hiLo, rev_predTst$predictions[,2], levels=c(-1, 1))

plot.roc(rocTrn, col='blue', legacy.axes = TRUE)
plot.roc(rocTst, col='red', add=TRUE)
legend("bottomright", legend=c("Training", "Test"),
        col=c("blue", "red"), lwd=2, cex=0.8, bty='n')

#best threshold from ROC
bThr<-coords(rocTrn, "best", ret="threshold", transpose = FALSE)
bThr <- as.numeric(bThr)

#Confusion Matrix at bThr for Trn and Tst dataset
a <- table(actual=revDTM_trn$hiLo, preds=rev_predTrn$predictions[,2]>bThr)
b <- table(actual=revDTM_tst$hiLo, preds=rev_predTst$predictions[,2]>bThr)

write.csv(a, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/bthr_trn.csv")
write.csv(b, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/bthr_tst.csv")

#Confusion Matrix at 0.5 for Trn and Tst dataset
c <- table(actual=revDTM_trn$hiLo, preds=rev_predTrn$predictions[,2]>0.5)
d <- table(actual=revDTM_tst$hiLo, preds=rev_predTst$predictions[,2]>0.5)

write.csv(c, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/0.5_trn.csv")
write.csv(d, "C:/Users/nikit/Desktop/IDS_572/Assignment4/Latest_Run/0.5_tst.csv")
```

#SVM Model
```{r}
library("e1071")
library("ROCR")
#model 1
system.time( svmBroad1 <- svm(as.factor(hiLo) ~., data = revDTM_trn
%>% select(-review_id), kernel="radial", cost=50, gamma=1, scale=FALSE, decision.values = TRUE)) 

revDTM_predTrn_svmBroad1<-predict(svmBroad1, revDTM_trn, decision.values = TRUE)
table(actual= revDTM_trn$hiLo, predicted= revDTM_predTrn_svmBroad1)
revDTM_predTst_svmBroad1<-predict(svmBroad1, revDTM_tst, decision.values = TRUE)
table(actual= revDTM_tst$hiLo, predicted= revDTM_predTst_svmBroad1)

svmtrn.roc <- prediction(attributes(revDTM_predTrn_svmBroad1)$decision.values, revDTM_trn$hiLo)
svmtrn.auc <- performance(svmtrn.roc, 'tpr', 'fpr')
aucsvmtrn <- performance(svmtrn.roc, 'auc')

auc(as.numeric(revDTM_trn$hiLo), as.numeric(revDTM_predTst_svmBroad1))

svmtst.roc <- prediction(attributes(revDTM_predTst_svmBroad1)$decision.values, revDTM_tst$hiLo)
svmtst.auc <- performance(svmtst.roc, 'tpr', 'fpr')
aucsvmtst <- performance(svmtst.roc, 'auc')

auc(as.numeric(revDTM_tst$hiLo), as.numeric(revDTM_predTst_svmBroad1))

plot(svmtrn.auc, col='green', add = TRUE, legacy.axes = TRUE)
plot(svmtst.auc, col='red', add=TRUE)
legend("bottomright", legend=c("Training", "Test"),
        col=c("green", "red"), lwd=2, cex=0.8, bty='n')
abline(a = 0, b = 1)

#model 2
system.time( svmBroad2 <- svm(as.factor(hiLo) ~., data = revDTM_trn
%>% select(-review_id), kernel="radial", cost=10, gamma=0.5, scale=FALSE, decision.values = TRUE)) 

revDTM_predTrn_svmBroad2<-predict(svmBroad2, revDTM_trn, decision.values = TRUE)
table(actual= revDTM_trn$hiLo, predicted= revDTM_predTrn_svmBroad2)
revDTM_predTst_svmBroad2<-predict(svmBroad2, revDTM_tst, decision.values = TRUE)
table(actual= revDTM_tst$hiLo, predicted= revDTM_predTst_svmBroad2)

svmtrn.roc <- prediction(attributes(revDTM_predTrn_svmBroad2)$decision.values, revDTM_trn$hiLo)
svm2trn.auc <- performance(svmtrn.roc, 'tpr', 'fpr')
aucsvmtrn2 <- performance(svmtrn.roc, 'auc')
auc(as.numeric(revDTM_trn$hiLo), as.numeric(revDTM_predTrn_svmBroad2))


svmtst.roc <- prediction(attributes(revDTM_predTst_svmBroad2)$decision.values, revDTM_tst$hiLo)
svm2tst.auc <- performance(svmtst.roc, 'tpr', 'fpr')
aucsvmtst2 <- performance(svmtst.roc, 'auc')
aucsvmtst2
auc(as.numeric(revDTM_tst$hiLo), as.numeric(revDTM_predTst_svmBroad2))


#ROC plot
plot(svm2trn.auc)
plot(svm2trn.auc, col='green', add = TRUE, legacy.axes = TRUE)
plot(svm2tst.auc, col='red', add=TRUE)
legend("bottomright", legend=c("Training", "Test"),
        col=c("green", "red"), lwd=2, cex=0.8, bty='n')
abline(a = 0, b = 1)

#Model 3

system.time( svmBroad3 <- svm(as.factor(hiLo) ~., data = revDTM_trn
%>% select(-review_id), kernel="radial", cost=10, gamma=1, scale=FALSE, decision.values = TRUE)) 

revDTM_predTrn_svmBroad3<-predict(svmBroad3, revDTM_trn, decision.values = TRUE)
table(actual= revDTM_trn$hiLo, predicted= revDTM_predTrn_svmBroad3)
revDTM_predTst_svmBroad3<-predict(svmBroad3, revDTM_tst, decision.values = TRUE)
table(actual= revDTM_tst$hiLo, predicted= revDTM_predTst_svmBroad3)

svmtrn.roc <- prediction(attributes(revDTM_predTrn_svmBroad3)$decision.values, revDTM_trn$hiLo)
svm3trn.auc <- performance(svmtrn.roc, 'tpr', 'fpr')
aucsvmtrn <- performance(svmtrn.roc, 'auc')
auc(as.numeric(revDTM_trn$hiLo), as.numeric(revDTM_predTrn_svmBroad3))

svmtst.roc <- prediction(attributes(revDTM_predTst_svmBroad3)$decision.values, revDTM_tst$hiLo)
svm3tst.auc <- performance(svmtst.roc, 'tpr', 'fpr')
aucsvmtst <- performance(svmtst.roc, 'auc')
auc(as.numeric(revDTM_tst$hiLo), as.numeric(revDTM_predTst_svmBroad3))

#ROC plot
plot(svm3trn.auc)
plot(svm3trn.auc, col='green', add = TRUE, legacy.axes = TRUE)
plot(svm3tst.auc, col='red', add=TRUE)
legend("bottomright", legend=c("Training", "Test"),
        col=c("green", "red"), lwd=2, cex=0.8, bty='n')
abline(a = 0, b = 1)

#Model 4

system.time( svmBroad4 <- svm(as.factor(hiLo) ~., data = revDTM_trn
%>% select(-review_id), kernel="radial", cost=1, gamma=2, scale=FALSE, decision.values = TRUE)) 

revDTM_predTrn_svmBroad4<-predict(svmBroad4, revDTM_trn, decision.values = TRUE)
table(actual= revDTM_trn$hiLo, predicted= revDTM_predTrn_svmBroad4)
revDTM_predTst_svmBroad4<-predict(svmBroad4, revDTM_tst, decision.values = TRUE)
table(actual= revDTM_tst$hiLo, predicted= revDTM_predTst_svmBroad4)

svmtrn.roc <- prediction(attributes(revDTM_predTrn_svmBroad4)$decision.values, revDTM_trn$hiLo)
svm4trn.auc <- performance(svmtrn.roc, 'tpr', 'fpr')
aucsvmtrn <- performance(svmtrn.roc, 'auc')
auc(as.numeric(revDTM_trn$hiLo), as.numeric(revDTM_predTrn_svmBroad4))


svmtst.roc <- prediction(attributes(revDTM_predTst_svmBroad4)$decision.values, revDTM_tst$hiLo)
svm4tst.auc <- performance(svmtst.roc, 'tpr', 'fpr')
aucsvmtst <- performance(svmtst.roc, 'auc')
auc(as.numeric(revDTM_tst$hiLo), as.numeric(revDTM_predTst_svmBroad4))

#ROC plot
plot(svm4trn.auc)
plot(svm4trn.auc, col='green', add = TRUE, legacy.axes = TRUE)
plot(svm4tst.auc, col='red', add=TRUE)
legend("bottomright", legend=c("Training", "Test"),
        col=c("green", "red"), lwd=2, cex=0.8, bty='n')
abline(a = 0, b = 1)
```

#Naive Bayes model on broader list of words
```{r message=FALSE, cache=TRUE}

library(pROC)
library(e1071)

#model 5a - without laplace
nbModel5<-naiveBayes(hiLo ~ ., data=revDTM_trn %>% select(-review_id))

#training data
rev_NBpredTrn<-predict(nbModel5, revDTM_trn, type = "raw")
cmtrn5 <- table(actual=revDTM_trn$hiLo, preds=rev_NBpredTrn[,2]>0.5)

#test data
rev_NBpredTst<-predict(nbModel5, revDTM_tst, type = "raw")
cmtst5<- table(actual=revDTM_tst$hiLo, preds=rev_NBpredTst[,2]>0.5)

#AUC values
auc(as.numeric(revDTM_trn$hiLo), rev_NBpredTrn[,2]) #67.02

auc(as.numeric(revDTM_tst$hiLo), rev_NBpredTst[,2]) #69.1


#model 5a - with laplace
nbModel5<-naiveBayes(hiLo ~ ., data=revDTM_trn %>% select(-review_id), laplace = 2)

#training data
rev_NBpredTrn<-predict(nbModel5, revDTM_trn, type = "raw")
cmtrn5 <- table(actual=revDTM_trn$hiLo, preds=rev_NBpredTrn[,2]>0.5)

#test data
rev_NBpredTst<-predict(nbModel5, revDTM_tst, type = "raw")
cmtst5<- table(actual=revDTM_tst$hiLo, preds=rev_NBpredTst[,2]>0.5)

#AUC values
auc(as.numeric(revDTM_trn$hiLo), rev_NBpredTrn[,2]) 

auc(as.numeric(revDTM_tst$hiLo), rev_NBpredTst[,2]) 


```

